# 需求

职位描述
1、遵循robots协议，参与爬虫系统的建设与优化，满足各类业务数据需求；
2、负责分布式爬虫系统的建设，优化数据调度、抓取、解析、存储全栈流程；
3、帮助团队攻克网页信息抽取技术算法的难关，提升海量数据系统的抓取效果与性能。
职位要求
1、本科及以上学历；
2、熟悉主流爬取技术及爬虫框架工具，如Selenium/Puppeteer/Scrapy/PhantomJS等；
3、熟悉Python/Java/Go/C++其中一种语言，具备扎实的编码能力；
4、熟悉常见反爬封禁策略，并具备相关的实战经验


你的简历和项目背景非常契合“爬虫工程师”岗位，尤其是分布式爬虫、反爬、数据采集等方向。结合你投递的岗位JD和你的项目/技能，面试官很可能会从以下几个方面出题：

---

## 1. 基础知识与原理

* 什么是爬虫？常见的爬虫类型有哪些？**爬虫是一个从网页获取数据的自动化程序，常见的爬虫有通用爬虫，分布式爬虫，深层爬虫等**
* robots.txt 是什么？爬虫如何遵守 robots 协议？**机器人协议是避免爬虫爬取涉及隐私敏感信息之类的协议，爬虫在进行爬取信息前需要遵守机器人协议**
* 什么是反爬虫？常见的反爬虫手段和应对策略有哪些？**反爬虫就是比如爬取一些网站的时候需要通过class或者id定为数据，其中有的id是动态的，不能准确或者持续性定为有的会有验证码的方式进行反爬**，**控制爬虫频率，模拟用户真实请求点击等**
* 分布式爬虫的原理是什么？为什么要做分布式？**分布式爬虫通过多台机器协同工作，将爬虫任务拆解为多个子任务并行执行**

---

## 2. 框架与工具实战

* Scrapy 的核心架构和工作流程？（调度器、下载器、中间件、管道等）
* Scrapy-Redis 如何实现分布式？Redis 在其中的作用？
* Playwright/Selenium/Puppeteer 的区别和适用场景？
* 如何用 Playwright/Selenium 抓取需要 JS 渲染的数据？
* Crawlab 的作用是什么？如何用它管理爬虫？
* 你在项目中如何实现爬虫的模块化、可扩展？

---

## 3. 编程能力与实战

* 手写一个简单的爬虫（如抓取某网站标题/列表页/详情页）
* 如何用多线程/多进程/协程提升爬虫效率？
* 如何用队列（如 Redis）实现任务分发和去重？
* 如何用 Python 实现断点续爬？
* 如何用正则表达式/BeautifulSoup/XPath 提取网页数据？

---

## 4. 反爬虫与封禁应对

* 遇到验证码/滑块/登录验证怎么处理？
* 如何伪装 User-Agent、IP 代理池、Cookie？
* 如何检测和应对网站的反爬策略？
* 你遇到过哪些反爬难题？是怎么解决的？

---

## 5. 数据存储与处理

* 爬取的数据如何存储？（MySQL、MongoDB、Redis等）
* 如何设计数据表结构？如何保证数据一致性？
* 如何处理大规模数据的清洗和去重？

---

## 6. 项目与团队协作

* 你在项目中负责哪些模块？遇到的最大技术难题是什么？如何解决的？
* 如何保证代码的健壮性和可维护性？
* 如何与前端/后端/产品/测试协作？

---

## 7. 拓展与综合能力

* 如果让你把本地爬虫改造成分布式，你会怎么设计？
* 如何监控爬虫运行状态和异常？如何自动重试？
* 如何保证爬虫的高可用和扩展性？
* 你对爬虫未来发展趋势怎么看？

---

## 8. 现场实操/算法题（可能性较小，但大厂会考）

* 字符串处理、正则表达式、数据结构（队列、栈、哈希表等）基础题
* 简单的多线程/多进程/协程代码实现
* 反爬策略设计与破解思路

---

## 9. 英语能力（如JD有要求）

* 可能会让你用英文简单介绍项目或技术原理

---

## 10. 行为面试

* 团队协作、抗压能力、学习能力、遇到挫折如何应对等

---

### 面试准备建议

1. 复习项目代码，能讲清楚每个模块的作用和技术细节。
2. 准备好1-2个你主导的技术难题和解决方案。
3. 多练习手写爬虫、数据提取、反爬策略等代码题。
4. 了解Scrapy-Redis、Crawlab、Playwright等工具的原理和用法。
5. 准备好英文自我介绍和项目介绍。
6. 关注岗位JD中的每一项要求，准备针对性回答。

---

如需面试题库、项目讲解模板、英文自我介绍、反爬实战技巧等资料，可以随时问我！
